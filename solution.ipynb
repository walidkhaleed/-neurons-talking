{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal, scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataSection(data, title, startTime=0, endTime=None, sampleRate=24e3):\n",
    "    if endTime is None:\n",
    "        time = np.linspace(0, len(data)/sampleRate, num=len(data))\n",
    "        data_section = data\n",
    "    else:\n",
    "        idxStart = int(startTime*sampleRate)\n",
    "        idxEnd = int(endTime*sampleRate)\n",
    "        data_section = data[idxStart: idxEnd]\n",
    "        time = np.linspace(startTime, endTime, num=(idxEnd - idxStart))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(time, data_section)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('time [s]')\n",
    "    ax.set_ylabel('voltage [uv]')\n",
    "    ax.grid(True)\n",
    "    return fig, ax\n",
    "\n",
    "def plotSectionMeanAndSTD(data, title, sampleRate=24e3):\n",
    "    dataMean = data.mean(axis=0)\n",
    "    time = np.linspace(0, len(dataMean)/sampleRate, num=len(dataMean))\n",
    "    dataSTD = data.std(axis=0)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.plot(time, dataMean, color='b')\n",
    "    ax1.plot(time, dataMean + dataSTD, 'r.')\n",
    "    ax1.plot(time, dataMean - dataSTD, 'r.')\n",
    "    ax1.set_title(title)\n",
    "    ax1.set_xlabel('time [s]')\n",
    "    ax1.set_ylabel('voltage [uv]')\n",
    "    ax1.grid(True)\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    ax2.plot(time, dataSTD)\n",
    "    ax2.set_xlabel('time [s]')\n",
    "    ax2.set_ylabel('STD')\n",
    "    ax2.grid(True)\n",
    "\n",
    "def getPeakSections(data, idxPeaks, windowSizeBefore, windowSizeAfter):\n",
    "    peakSections = []\n",
    "    for i in idxPeaks:\n",
    "        peakSections.append(data[i - windowSizeBefore: i + windowSizeAfter])\n",
    "    return np.array(peakSections)\n",
    "\n",
    "def removeOutOfBoundIdx(idx, lowBound, upBound):\n",
    "    '''Remove the idx that are too close to the begining or end \n",
    "    defined by lowBound and upBound.\n",
    "    Needed to avoid index out of bound error when cutting data into small sections.\n",
    "    '''\n",
    "    return idx[np.logical_and(idx > lowBound, idx < upBound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate = 24e3\n",
    "heightThreshold = 55\n",
    "distanceThreshold = 10\n",
    "windowSizeBefore = 30\n",
    "windowSizeAfter = 70\n",
    "numSpikeTypes = 2\n",
    "dataFile = 'sample_4.mat'\n",
    "numPC = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(dataFile)\n",
    "origData = data['data'].flatten()\n",
    "spike_times = data['spike_times'][0][0][0]\n",
    "spike_class = data['spike_class'][0][0][0]\n",
    "spike_times_type0 = spike_times[np.where(spike_class == 0)]\n",
    "spike_times_type0 = removeOutOfBoundIdx(\n",
    "    spike_times_type0, windowSizeBefore, len(origData) - windowSizeAfter - 80)\n",
    "\n",
    "spike_times_type1 = spike_times[np.where(spike_class == 1)]\n",
    "spike_times_type1 = removeOutOfBoundIdx(\n",
    "    spike_times_type1, windowSizeBefore, len(origData) - windowSizeAfter - 80)\n",
    "\n",
    "spike_times_type2 = spike_times[np.where(spike_class == 2)]\n",
    "spike_times_type2 = removeOutOfBoundIdx(\n",
    "    spike_times_type2, windowSizeBefore, len(origData) - windowSizeAfter - 80)\n",
    "\n",
    "print(f'dataset loaded, origial data shape: {origData.shape}')\n",
    "\n",
    "recLength = len(origData) / sampleRate\n",
    "print(f'recording length {recLength:8.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeSectionType0 = getPeakSections(origData, spike_times_type0, \n",
    "    windowSizeBefore, windowSizeAfter + 80)\n",
    "spikeSectionType1 = getPeakSections(origData, spike_times_type1, \n",
    "    windowSizeBefore, windowSizeAfter + 80)\n",
    "spikeSectionType2 = getPeakSections(origData, spike_times_type2, \n",
    "    windowSizeBefore, windowSizeAfter + 80)\n",
    "plotSectionMeanAndSTD(spikeSectionType0, 'avg waveform type 0')\n",
    "plotSectionMeanAndSTD(spikeSectionType1, 'avg waveform type 1')\n",
    "plotSectionMeanAndSTD(spikeSectionType2, 'avg waveform type 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visulize raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDataSection(origData, 'raw data', 0.5, 1, sampleRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = scipy.signal.butter(8, 40*2*np.pi, 'highpass', fs=sampleRate, output='sos')\n",
    "filteredData = scipy.signal.sosfilt(sos, origData)\n",
    "\n",
    "fiteredSectionType0 = getPeakSections(filteredData, spike_times_type0, \n",
    "    windowSizeBefore, windowSizeAfter + 80)\n",
    "fiteredSectionType1 = getPeakSections(filteredData, spike_times_type1, \n",
    "    windowSizeBefore, windowSizeAfter + 80)\n",
    "fiteredSectionType2 = getPeakSections(filteredData, spike_times_type2, \n",
    "    windowSizeBefore, windowSizeAfter + 80)\n",
    "\n",
    "plotDataSection(fiteredSectionType0[3, :], 'filtered waveform type 0')\n",
    "plotDataSection(fiteredSectionType0[4, :], 'filtered waveform type 0')\n",
    "plotDataSection(fiteredSectionType0[5, :], 'filtered waveform type 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxPeaks, peakProperties = scipy.signal.find_peaks(\n",
    "    origData, height=heightThreshold, distance=distanceThreshold)\n",
    "idxPeaks = idxPeaks[idxPeaks > windowSizeBefore]\n",
    "print(f'number of peaks found: {len(idxPeaks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut out each peak as small section of data, then the remaining data is considered as background noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakSections = getPeakSections(origData, idxPeaks, windowSizeBefore, windowSizeAfter)\n",
    "\n",
    "backgroundNoise = origData.copy()\n",
    "for i in idxPeaks:\n",
    "    backgroundNoise[i - windowSizeBefore: i + windowSizeAfter] = np.Inf      \n",
    "backgroundNoise = backgroundNoise[backgroundNoise != np.Inf]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDataSection(backgroundNoise, 'background noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA to the peak sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=numPC)\n",
    "pca.fit(peakSections)\n",
    "peakPC = pca.transform(peakSections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply K-Mean clustering on the PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeanCluster = KMeans(n_clusters=numSpikeTypes, n_init=10)\n",
    "kMeanCluster.fit(peakPC)\n",
    "# kMeanCluster.fit(peakSections)\n",
    "for i in range(numSpikeTypes):\n",
    "    plotDataSection(\n",
    "        pca.inverse_transform(kMeanCluster.cluster_centers_[i]), f'spike type {i}')\n",
    "    # plotDataSection(kMeanCluster.cluster_centers_[i], f'spike type {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the clustering result to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare number of peaks found through clustering to ground truth\n",
    "print('compare number of peaks found through clustering to ground truth')\n",
    "print(f'{sum(kMeanCluster.labels_ == 0)} type 0 spikes were found through clutering')\n",
    "print(f'{sum(kMeanCluster.labels_ == 1)} type 1 spikes were found through clutering')\n",
    "\n",
    "print(f'{len(spike_times_type0)} type 0 spikes in ground truth')\n",
    "print(f'{len(spike_times_type1)} type 1 spikes in ground truth')\n",
    "print(f'{len(spike_times_type2)} type 2 spikes in ground truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(pred, groundTruth, tolerance):\n",
    "    numTruePositive = 0    \n",
    "    numFalsePositive = 0\n",
    "    notMatchedGroundTruth = groundTruth.copy()\n",
    "    listFalsePositive = []\n",
    "    for singlePred in pred:\n",
    "        matchingScore = np.abs(notMatchedGroundTruth - singlePred)\n",
    "        allMatching = notMatchedGroundTruth[matchingScore <= tolerance]\n",
    "        if allMatching.size > 0:\n",
    "            bestMatchIdx = np.argmin(matchingScore)\n",
    "            bestMatch = notMatchedGroundTruth[bestMatchIdx]\n",
    "            notMatchedGroundTruth = np.delete(notMatchedGroundTruth, bestMatchIdx)\n",
    "            numTruePositive += 1\n",
    "        else:\n",
    "            numFalsePositive += 1\n",
    "            listFalsePositive.append(singlePred)\n",
    "\n",
    "    listFalseNegative = notMatchedGroundTruth\n",
    "    numFalseNegative = len(listFalseNegative)\n",
    "    print(f'    number of True Positive: {numTruePositive} / {len(groundTruth)}')\n",
    "    print(f'    number of False Positive: {numFalsePositive}, False Negative: {numFalseNegative}')\n",
    "    return (numTruePositive, numFalsePositive, \n",
    "        numFalseNegative, listFalsePositive, listFalseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type0PeakIdx = idxPeaks[kMeanCluster.labels_ == 0]\n",
    "type1PeakIdx = idxPeaks[kMeanCluster.labels_ == 1]\n",
    "tolerance = windowSizeBefore + windowSizeAfter\n",
    "\n",
    "print('confusion matrix for type0 (clusting) and type1 (ground truth):')\n",
    "numTruePositive, numFalsePositive, numFalseNegative, \\\n",
    "    listFalsePositive, listFalseNegative = getConfusionMatrix(\n",
    "        type0PeakIdx, spike_times_type1, tolerance)\n",
    "\n",
    "print('confusion matrix for type1 (clusting) and type2 (ground truth):')\n",
    "numTruePositive, numFalsePositive, numFalseNegative, \\\n",
    "    listFalsePositive, listFalseNegative = getConfusionMatrix(\n",
    "        type1PeakIdx, spike_times_type2, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPeak(origData, peakIdx, title, windowSizeBefore, windowSizeAfter, sampleRate=24e3):\n",
    "    data = origData[peakIdx - windowSizeBefore: peakIdx + windowSizeAfter]\n",
    "    plotDataSection(data, title, sampleRate=sampleRate)\n",
    "\n",
    "numVisualize = 2\n",
    "for i in range(numVisualize):\n",
    "    plotPeak(origData, listFalsePositive[i], f'False Positive case {i}', \n",
    "        windowSizeBefore, windowSizeAfter, sampleRate)\n",
    "    plotPeak(origData, listFalseNegative[i], f'False Negative case {i}', \n",
    "        windowSizeBefore, windowSizeAfter, sampleRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Basic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af4be68bc83ee8b4990ef241d39a0895e3dbdba656f322636630ee59a6e6e332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
